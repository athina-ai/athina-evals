{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from athina.steps import Debug, Fn, Chain, PromptExecution, Map, ExtractJsonFromString\n",
    "from athina.steps.llm import PromptTemplate, PromptMessage\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.keys import OpenAiApiKey\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv(\"OPENAI_API_KEY\"))\n",
    "openai_service = OpenAiService()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAIN 1: \n",
    "# - Generate a list of car makes and models\n",
    "# - Extract the car makes\n",
    "# - For each car make, generate a tweet using an LLM\n",
    "def generate_tweet(topic: str) -> str:\n",
    "    return openai_service.chat_completion(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Generate a marketing tweet about {topic}\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\")\n",
    "\n",
    "steps = [\n",
    "    # Generate a list of cars\n",
    "    PromptExecution(\n",
    "        llm_service=openai_service,\n",
    "        template=PromptTemplate(\n",
    "            messages=[\n",
    "                PromptMessage(role=\"system\", content=\"Generate a list of {items} structured as a JSON array.\")\n",
    "            ]\n",
    "        ),\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        model_options={},\n",
    "        output_key=\"cars\",\n",
    "    ),\n",
    "    ExtractJsonFromString(input_key=\"cars\", output_key=\"cars\"),\n",
    "    Debug(),\n",
    "    # Extract the make of the car for each car in the list\n",
    "    Fn(\n",
    "        fn=lambda cars: [car['make'] for car in cars],\n",
    "        input_key=\"cars\",\n",
    "        output_key=\"makes\"\n",
    "    ),\n",
    "    # Generate a marketing tweet for each car make\n",
    "    Map(\n",
    "        input_key=\"makes\", \n",
    "        fn=generate_tweet,\n",
    "        output_key=\"tweets\"\n",
    "        ),\n",
    "    Debug(),\n",
    "]\n",
    "\n",
    "chain = Chain(sequence=steps)\n",
    "result_chain = chain.run(inputs={\n",
    "    \"items\": \"4 cars with make, model, and license number.\"\n",
    "})\n",
    "\n",
    "makes = result_chain.get_output(\"makes\")\n",
    "tweets = result_chain.get_output(\"tweets\")\n",
    "\n",
    "print(\"context\", result_chain.get_context())\n",
    "print(\"makes: \", makes)\n",
    "print(\"tweets: \", tweets)\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_chain.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAIN 2: \n",
    "# - Get news from an API. (mocked function)\n",
    "# - Generate summaries for the news articles.\n",
    "# - Generate an email combining all the summaries.\n",
    "\n",
    "def get_news_from_api(topic: str) -> List[Dict[str, str]]:\n",
    "    return [\n",
    "        {\n",
    "            \"title\": \"OpenAI has been acquired by Microsoft\",\n",
    "            \"content\": \"Content 1\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Google is launching a new AI research lab in Paris\",\n",
    "            \"content\": \"Content 2\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Meta has just released Llama 4, a multimodal AI model\",\n",
    "            \"content\": \"Content 3\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Apple is investing $1 billion in a new AI research center in Berlin\",\n",
    "            \"content\": \"Content 4\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "steps = [\n",
    "    # Get news articles from an API\n",
    "    Fn(\n",
    "        fn=get_news_from_api,\n",
    "        input_key=\"topic\",\n",
    "        output_key=\"news\"\n",
    "    ),\n",
    "    Debug(),\n",
    "    # Extract the title for each news article\n",
    "    Map(\n",
    "        input_key=\"news\",\n",
    "        fn=lambda news_item: news_item['title'],\n",
    "        output_key=\"news_titles\"\n",
    "    ),\n",
    "    # Convert the news items array into a string\n",
    "    Fn(\n",
    "        input_key=\"news_titles\",\n",
    "        fn=lambda news_titles: \"\\n\".join(news_titles),\n",
    "        output_key=\"news_titles_str\"\n",
    "    ),\n",
    "    Debug(),\n",
    "    # Generate a summary for each news title\n",
    "    PromptExecution(\n",
    "        llm_service=openai_service,\n",
    "        template=PromptTemplate.simple(\"Generate a summary for the following news titles: {news_titles_str}. Return a json array. Each element of the array should have these fields: title, summary\"),\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        output_key=\"summaries\",\n",
    "    ),\n",
    "    # Extract the summaries as a JSON array of objects\n",
    "    ExtractJsonFromString(input_key=\"summaries\", output_key=\"summaries_list\"),\n",
    "    # Get the summary string (without the title) for each generated summary\n",
    "    Map(\n",
    "        input_key=\"summaries_list\",\n",
    "        fn=lambda summary: summary['summary'],\n",
    "        output_key=\"summaries_without_titles\",\n",
    "    ),\n",
    "    Debug(),\n",
    "    # Generate an email combining all the summaries\n",
    "    PromptExecution(\n",
    "        llm_service=openai_service,\n",
    "        template=PromptTemplate.simple(\"Generate a weekly roundup newsletter email from the following summaries: {summaries_without_titles}.\"),\n",
    "        model=\"gpt-4o\",\n",
    "        output_key=\"email\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "chain = Chain(sequence=steps)\n",
    "result_chain = chain.run(inputs={ \"topic\": \"AI\" })\n",
    "print(\"context\", result_chain.get_context())\n",
    "\n",
    "res = result_chain.get_output(\"email\")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_chain.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
