{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat_g/ai_repos/athina-evals/athina-evals/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllms\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai_service\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAiService\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     DoesResponseAnswerQuery,\n\u001b[1;32m      5\u001b[0m     ContextContainsEnoughInformation,\n\u001b[1;32m      6\u001b[0m     Faithfulness,\n\u001b[1;32m      7\u001b[0m     RagasContextRelevancy,\n\u001b[1;32m      8\u001b[0m     RagasAnswerRelevancy,\n\u001b[1;32m      9\u001b[0m     RagasContextPrecision,\n\u001b[1;32m     10\u001b[0m     RagasFaithfulness,\n\u001b[1;32m     11\u001b[0m     RagasContextRecall,\n\u001b[1;32m     12\u001b[0m     RagasAnswerSemanticSimilarity,\n\u001b[1;32m     13\u001b[0m     RagasAnswerCorrectness,\n\u001b[1;32m     14\u001b[0m     RagasHarmfulness,\n\u001b[1;32m     15\u001b[0m     RagasMaliciousness,\n\u001b[1;32m     16\u001b[0m     RagasCoherence,\n\u001b[1;32m     17\u001b[0m     RagasConciseness\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m \u001b[39mimport\u001b[39;00m FunctionEvaluator\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloaders\u001b[39;00m \u001b[39mimport\u001b[39;00m RagLoader, ResponseLoader, RagasLoader\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/evals/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummary_accuracy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryAccuracy\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroundedness\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m  \u001b[39mimport\u001b[39;00m Groundedness\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext_relevancy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasContextRelevancy\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manswer_relevancy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasAnswerRelevancy\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext_precision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasContextPrecision\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/evals/ragas/context_relevancy/evaluator.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterfaces\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragas_evaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasEvaluator\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meval_type\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasEvalTypeId\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mathina\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetric_type\u001b[39;00m \u001b[39mimport\u001b[39;00m MetricType\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/evals/ragas/ragas_evaluator.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_evaluator\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseEvaluator\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_openai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllms\u001b[39;00m \u001b[39mimport\u001b[39;00m LangchainLLM\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragas\u001b[39;00m \u001b[39mimport\u001b[39;00m evaluate\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.evals import (\n",
    "    DoesResponseAnswerQuery,\n",
    "    ContextContainsEnoughInformation,\n",
    "    Faithfulness\n",
    ")\n",
    "\n",
    "from athina.evals import FunctionEvaluator\n",
    "from athina.loaders import RagLoader, ResponseLoader, RagasLoader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "from athina.interfaces.athina import AthinaFilters\n",
    "import pandas as pd\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Paris is the capital of france\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_raw_data_ragas = RagasLoader().load_dict(raw_data_ragas)\n",
    "pd.DataFrame(dataset_raw_data_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    }\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run(**data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas_with_expected_response = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "        \"expected_response\": \"France is in europe. Paris is it's capital\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is Tesla? Who founded it?\",\n",
    "        \"contexts\": [\"Tesla is the electric car company. Tesla is registerd in United States\", \"Elon Musk founded it\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "        \"expected_response\": \"Tesla is an electric car company. Elon Musk founded it.\"\n",
    "    },\n",
    "]\n",
    "dataset_raw_data_ragas_with_expected_response = RagasLoader().load_dict(raw_data_ragas_with_expected_response)\n",
    "pd.DataFrame(dataset_raw_data_ragas_with_expected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextPrecision(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasFaithfulness(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRecall(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerSemanticSimilarity(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerCorrectness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasHarmfulness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasMaliciousness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasCoherence(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasConciseness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": \"Greece is often called the cradle of Western civilization.\",\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": \"Tesla Model 3 is a fully electric car.\",\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": \"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\",\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = RagLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "ContextContainsEnoughInformation(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response answers the user query sufficiently\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "DoesResponseAnswerQuery(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response is faithful to the information provided to it\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "Faithfulness(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import ResponseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsNone\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"This text does not contain the specified keyword.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"This is a text without any specified search word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsNone(keywords=[\"keyword\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Contains\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"The keyword YC present in this text.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"This text does not contain the specified word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "Contains(keyword=\"YC\").run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsAll\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"This text contains both keyword1 and keyword2.\"},\n",
    "    {\"response\": \"This text does not contain all specified keywords.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsAll(keywords=[\"keyword1\", \"keyword2\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": '{\"key\": \"value\"}'},\n",
    "    {\"response\": '{\"invalid : \"json\"}'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Contact us at contact@example.com.\"},\n",
    "    {\"response\": \"This text does not contain any email address.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": '{\"key\": \"value\"}'},\n",
    "    {\"response\": 'invalid_json'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "IsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"john.doe@example.com\"},\n",
    "    {\"response\": \"invalid.email\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "IsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"For more information, visit https://example.com.\"},\n",
    "    {\"response\": \"This text does not contain any link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsValidLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Visit our official website at http://example.com.\"},\n",
    "    {\"response\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"response\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsValidLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import NoInvalidLinks\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Visit our website at https://example.com.\"},\n",
    "    {\"response\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"response\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "\n",
    "# Example calls\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ApiCall\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Response to be sent to the your own API based evaluator\"}\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ApiCall(url=\"https://8e714940905f4022b43267e348b8a71.api.mockbin.io/\", payload={\"evaluator\": \"custom_api_based_evaluator\"}, headers={\"Authorization\": \"Bearer token\"}).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Equals\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"This is the expected response\"},\n",
    "    {\"response\": \"This is an unexpected response\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "Equals(expected_response=\"This is the expected response\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import StartsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"The text starts with this substring.\"},\n",
    "    {\"response\": \"This text does not start with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "StartsWith(substring=\"The text starts with\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import EndsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"The text ends with this substring.\"},\n",
    "    {\"response\": \"This text does not end with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "EndsWith(substring=\"with this substring.\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthLessThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Short text\"},\n",
    "    {\"response\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "LengthLessThan(max_length=20).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthGreaterThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Short text\"},\n",
    "    {\"response\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "LengthGreaterThan(min_length=20).run_batch(data=dataset).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
