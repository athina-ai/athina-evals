{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from athina.evals import (\n",
    "    DoesResponseAnswerQuery,\n",
    "    ContextContainsEnoughInformation,\n",
    "    Faithfulness,\n",
    "    RagasContextRelevancy,\n",
    "    RagasAnswerRelevancy,\n",
    "    RagasContextPrecision,\n",
    "    RagasFaithfulness,\n",
    "    RagasContextRecall,\n",
    "    RagasAnswerSemanticSimilarity,\n",
    "    RagasAnswerCorrectness,\n",
    "    RagasHarmfulness,\n",
    "    RagasMaliciousness,\n",
    "    RagasCoherence,\n",
    "    RagasConciseness\n",
    ")\n",
    "from athina.loaders import Loader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"Who founded Tesla\",\n",
    "        \"context\": [\n",
    "            \"Tesla is an automative manufacturer.\",\n",
    "            \"Tesla was founded by Elon Musk in 2003 and is headquartered in Palo Alto, California.\",\n",
    "            \"Tesla makes electric cars.\",\n",
    "        ],\n",
    "        \"response\": \"Tesla is an electric car company\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": [\"France is the country in europe known for delicious cuisine\", \"Paris is the capital of france\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_raw_data = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_raw_data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"query\": \"Where is France and what is its capital?\",\n",
    "        \"context\": [\n",
    "            \"France is a country in Europe known for delicious cuisine\",\n",
    "            \"The capital of France is Paris.\", \n",
    "            \"French fries were not invented in France.\"\n",
    "        ],\n",
    "        \"response\": \"Paris is the capital of France\",\n",
    "    }\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run(**data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas_with_expected_response = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is its capital?\",\n",
    "        \"context\": [\n",
    "            \"France is a country in Europe known for delicious cuisine\",\n",
    "            \"The capital of France is Paris.\", \n",
    "            \"French fries were not invented in France.\"\n",
    "        ],\n",
    "        \"response\": \"Paris is the capital of France\",\n",
    "        \"expected_response\": \"France is in europe. Paris is it's capital\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is Tesla? Who founded it?\",\n",
    "        \"context\": [\n",
    "            \"Tesla is an electric car company.\", \n",
    "            \"Tesla is registered in United States\", \n",
    "            \"Elon Musk founded Tesla\"\n",
    "        ],\n",
    "        \"response\": \"Tesla is an electric car company\",\n",
    "        \"expected_response\": \"Tesla is an electric car company, founded by Elon Musk.\"\n",
    "    },\n",
    "]\n",
    "ragas_dataset_with_expected_response = Loader().load_dict(raw_data_ragas_with_expected_response)\n",
    "pd.DataFrame(ragas_dataset_with_expected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextPrecision(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasFaithfulness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRecall(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerSemanticSimilarity(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerCorrectness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasHarmfulness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasMaliciousness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasCoherence(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasConciseness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": [\"Greece is often called the cradle of Western civilization.\"],\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": [\"Tesla Model 3 is a fully electric car.\"],\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": [\"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\"],\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"text\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"text\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsNone\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"text\": \"This text does not contain the specified keyword.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This is a text without any specified search word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsNone(keywords=[\"keyword\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Contains\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"text\": \"The keyword YC present in this text.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This text does not contain the specified word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "Contains(keyword=\"YC\").run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsAll\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"This text contains both keyword1 and keyword2.\"},\n",
    "    {\"text\": \"This text does not contain all specified keywords.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsAll(keywords=[\"keyword1\", \"keyword2\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": '{\"key\": \"value\"}'},\n",
    "    {\"text\": '{\"invalid : \"json\"}'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Contact us at contact@example.com.\"},\n",
    "    {\"text\": \"This text does not contain any email address.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": '{\"key\": \"value\"}'},\n",
    "    {\"text\": 'invalid_json'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "IsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"john.doe@example.com\"},\n",
    "    {\"text\": \"invalid.email\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "IsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"For more information, visit https://example.com.\"},\n",
    "    {\"text\": \"This text does not contain any link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsValidLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Visit our official website at http://example.com.\"},\n",
    "    {\"text\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"text\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsValidLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import NoInvalidLinks\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Visit our website at https://example.com.\"},\n",
    "    {\"text\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"text\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "\n",
    "# Example calls\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ApiCall\n",
    "from athina.loaders import ResponseLoader\n",
    "\n",
    "# API call to your own API based evaluator. Raw data must contain response and optionally the query, context and expected_response\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"Response to be sent to the your own API based evaluator\",\n",
    "        \"query\": \"Query to be sent to the your own API based evaluator\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ApiCall(url=\"https://8e714940905f4022b43267e348b8a713.api.mockbin.io/\", payload={\"evaluator\": \"custom_api_based_evaluator\"}, headers={\"Authorization\": \"Bearer token\"}).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Equals\n",
    "from athina.loaders import TextLoader\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"This is the expected response\"},\n",
    "    {\"text\": \"This is an unexpected response\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "Equals(expected_text=\"This is the expected response\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import StartsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"The text starts with this substring.\"},\n",
    "    {\"text\": \"This text does not start with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "StartsWith(substring=\"The text starts with\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import EndsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"The text ends with this substring.\"},\n",
    "    {\"text\": \"This text does not end with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "EndsWith(substring=\"with this substring.\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthLessThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Short text\"},\n",
    "    {\"text\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "LengthLessThan(max_length=20).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthGreaterThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Short text\"},\n",
    "    {\"text\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "LengthGreaterThan(min_length=20).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthBetween\n",
    "\n",
    "# Example data\n",
    "data = [\n",
    "    {\"text\": \"Short text\"},\n",
    "    {\"text\": \"This is a long text.\"},\n",
    "    {\"text\": \"This is a very long text. The Great Barrier Reef is the world's largest coral reef system composed of over 2,900 individual reefs and 900 islands stretching for over 2,300 kilometers.\"}\n",
    "]\n",
    " \n",
    "LengthBetween(min_length=20, max_length=50).run_batch(data=data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import OneLine\n",
    "\n",
    "# Example data\n",
    "data = [\n",
    "    {\"text\": \"This is a single line text.\"},\n",
    "    {\"text\": \"The Great Barrier Reef is the world's largest coral reef system.\\n It is composed of over 2,900 individual reefs and 900 islands stretching for over 2,300 kilometers.\"}\n",
    "]\n",
    " \n",
    "OneLine().run_batch(data=data).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
