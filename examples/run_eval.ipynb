{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat_g/athina/repos/athina-evals/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/akshat_g/athina/repos/athina-evals/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from athina.evals import (\n",
    "    DoesResponseAnswerQuery,\n",
    "    ContextContainsEnoughInformation,\n",
    "    Faithfulness,\n",
    "    RagasContextRelevancy,\n",
    "    RagasAnswerRelevancy,\n",
    "    RagasContextPrecision,\n",
    "    RagasFaithfulness,\n",
    "    RagasContextRecall,\n",
    "    RagasAnswerSemanticSimilarity,\n",
    "    RagasAnswerCorrectness,\n",
    "    RagasHarmfulness,\n",
    "    RagasMaliciousness,\n",
    "    RagasCoherence,\n",
    "    RagasConciseness\n",
    ")\n",
    "from athina.loaders import Loader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>expected_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who founded Tesla</td>\n",
       "      <td>[Tesla is an automative manufacturer., Tesla w...</td>\n",
       "      <td>Tesla is an electric car company</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>[France is the country in europe known for del...</td>\n",
       "      <td>France is in western Europe and Paris is its c...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       query  \\\n",
       "0                          Who founded Tesla   \n",
       "1  Where is France and what is it's capital?   \n",
       "\n",
       "                                             context  \\\n",
       "0  [Tesla is an automative manufacturer., Tesla w...   \n",
       "1  [France is the country in europe known for del...   \n",
       "\n",
       "                                            response expected_response  \n",
       "0                   Tesla is an electric car company              None  \n",
       "1  France is in western Europe and Paris is its c...              None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"Who founded Tesla\",\n",
    "        \"context\": [\n",
    "            \"Tesla is an automative manufacturer.\",\n",
    "            \"Tesla was founded by Elon Musk in 2003 and is headquartered in Palo Alto, California.\",\n",
    "            \"Tesla makes electric cars.\",\n",
    "        ],\n",
    "        \"response\": \"Tesla is an electric car company\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": [\"France is the country in europe known for delicious cuisine\", \"Paris is the capital of france\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_raw_data = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]evaluating with [answer_relevancy]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view your dataset at: https://app.athina.ai/datasets/48025c91-bd42-4cc6-83e9-fdd3c8dfe55a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>expected_response</th>\n",
       "      <th>display_name</th>\n",
       "      <th>failed</th>\n",
       "      <th>grade_reason</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model</th>\n",
       "      <th>ragas_answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who founded Tesla</td>\n",
       "      <td>[Tesla is an automative manufacturer., Tesla was founded by Elon Musk in 2003 and is headquartered in Palo Alto, California., Tesla makes electric cars.]</td>\n",
       "      <td>Tesla is an electric car company</td>\n",
       "      <td>None</td>\n",
       "      <td>Ragas Answer Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details</td>\n",
       "      <td>2814</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.820244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>[France is the country in europe known for delicious cuisine, Paris is the capital of france]</td>\n",
       "      <td>France is in western Europe and Paris is its capital</td>\n",
       "      <td>None</td>\n",
       "      <td>Ragas Answer Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details</td>\n",
       "      <td>2780</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.975397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       query  \\\n",
       "0                          Who founded Tesla   \n",
       "1  Where is France and what is it's capital?   \n",
       "\n",
       "                                                                                                                                                     context  \\\n",
       "0  [Tesla is an automative manufacturer., Tesla was founded by Elon Musk in 2003 and is headquartered in Palo Alto, California., Tesla makes electric cars.]   \n",
       "1                                                              [France is the country in europe known for delicious cuisine, Paris is the capital of france]   \n",
       "\n",
       "                                               response expected_response  \\\n",
       "0                      Tesla is an electric car company              None   \n",
       "1  France is in western Europe and Paris is its capital              None   \n",
       "\n",
       "             display_name failed  \\\n",
       "0  Ragas Answer Relevancy   None   \n",
       "1  Ragas Answer Relevancy   None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                  grade_reason  \\\n",
       "0  A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details   \n",
       "1  A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details   \n",
       "\n",
       "   runtime          model  ragas_answer_relevancy  \n",
       "0     2814  gpt-3.5-turbo                0.820244  \n",
       "1     2780  gpt-3.5-turbo                0.975397  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_raw_data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"query\": \"Where is France and what is its capital?\",\n",
    "        \"context\": [\n",
    "            \"France is a country in Europe known for delicious cuisine\",\n",
    "            \"The capital of France is Paris.\", \n",
    "            \"French fries were not invented in France.\"\n",
    "        ],\n",
    "        \"response\": \"Paris is the capital of France\",\n",
    "    }\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run(**data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas_with_expected_response = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is its capital?\",\n",
    "        \"context\": [\n",
    "            \"France is a country in Europe known for delicious cuisine\",\n",
    "            \"The capital of France is Paris.\", \n",
    "            \"French fries were not invented in France.\"\n",
    "        ],\n",
    "        \"response\": \"Paris is the capital of France\",\n",
    "        \"expected_response\": \"France is in europe. Paris is it's capital\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is Tesla? Who founded it?\",\n",
    "        \"context\": [\n",
    "            \"Tesla is an electric car company.\", \n",
    "            \"Tesla is registered in United States\", \n",
    "            \"Elon Musk founded Tesla\"\n",
    "        ],\n",
    "        \"response\": \"Tesla is an electric car company\",\n",
    "        \"expected_response\": \"Tesla is an electric car company, founded by Elon Musk.\"\n",
    "    },\n",
    "]\n",
    "ragas_dataset_with_expected_response = Loader().load_dict(raw_data_ragas_with_expected_response)\n",
    "pd.DataFrame(ragas_dataset_with_expected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextPrecision(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasFaithfulness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRecall(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerSemanticSimilarity(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerCorrectness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasHarmfulness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasMaliciousness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasCoherence(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasConciseness(model=eval_model).run_batch(data=ragas_dataset_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": [\"Greece is often called the cradle of Western civilization.\"],\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": [\"Tesla Model 3 is a fully electric car.\"],\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": [\"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\"],\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"text\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"text\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsNone\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"text\": \"This text does not contain the specified keyword.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This is a text without any specified search word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsNone(keywords=[\"keyword\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Contains\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"text\": \"The keyword YC present in this text.\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"This text does not contain the specified word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "Contains(keyword=\"YC\").run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsAll\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"This text contains both keyword1 and keyword2.\"},\n",
    "    {\"text\": \"This text does not contain all specified keywords.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsAll(keywords=[\"keyword1\", \"keyword2\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": '{\"key\": \"value\"}'},\n",
    "    {\"text\": '{\"invalid : \"json\"}'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Contact us at contact@example.com.\"},\n",
    "    {\"text\": \"This text does not contain any email address.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": '{\"key\": \"value\"}'},\n",
    "    {\"text\": 'invalid_json'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "IsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"john.doe@example.com\"},\n",
    "    {\"text\": \"invalid.email\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "IsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"For more information, visit https://example.com.\"},\n",
    "    {\"text\": \"This text does not contain any link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsValidLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Visit our official website at http://example.com.\"},\n",
    "    {\"text\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"text\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "ContainsValidLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import NoInvalidLinks\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Visit our website at https://example.com.\"},\n",
    "    {\"text\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"text\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "\n",
    "# Example calls\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ApiCall\n",
    "from athina.loaders import ResponseLoader\n",
    "\n",
    "# API call to your own API based evaluator. Raw data must contain response and optionally the query, context and expected_response\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"Response to be sent to the your own API based evaluator\",\n",
    "        \"query\": \"Query to be sent to the your own API based evaluator\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ApiCall(url=\"https://8e714940905f4022b43267e348b8a713.api.mockbin.io/\", payload={\"evaluator\": \"custom_api_based_evaluator\"}, headers={\"Authorization\": \"Bearer token\"}).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Equals\n",
    "from athina.loaders import TextLoader\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"This is the expected response\"},\n",
    "    {\"text\": \"This is an unexpected response\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "Equals(expected_text=\"This is the expected response\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import StartsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"The text starts with this substring.\"},\n",
    "    {\"text\": \"This text does not start with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "StartsWith(substring=\"The text starts with\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import EndsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"The text ends with this substring.\"},\n",
    "    {\"text\": \"This text does not end with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "EndsWith(substring=\"with this substring.\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthLessThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Short text\"},\n",
    "    {\"text\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "LengthLessThan(max_length=20).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthGreaterThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"text\": \"Short text\"},\n",
    "    {\"text\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = TextLoader().load_dict(raw_data)\n",
    "LengthGreaterThan(min_length=20).run_batch(data=dataset).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
